<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<title>
  
     Un caso aplicado a los metódos de ensamble | 
    Un Data Scientist Dice
  
</title><meta name="description" content="Machine Learnign and Statistical modelling."><meta name="author" content="Daniel Jiménez">

<link rel="apple-touch-icon" href="/apple-touch-icon.png" sizes="180x180">
<link rel="icon" href="/favicon-32x32.png " sizes="32x32" type="image/png">
<link rel="icon" href="/favicon-16x16.png" sizes="16x16" type="image/png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#0c344b">
<link rel="icon" href="/favicon.ico">


    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/themes/prism.min.css">
    



    
        
            <link rel="stylesheet" href="/dist/main.37ab3f61b95417873748.min.css">
        
    




<link rel="canonical" href="https://danieljimenezm.com/post/2020-02-10-ensamble/"><meta property="og:title" content="Un caso aplicado a los metódos de ensamble" />
<meta property="og:description" content="Metódos de ensamble Uno de los problemas al trabajar con machine learning consiste en optimizar el accuracy de los modelos y para ello una de las mejores vias es trabajar con modelos de ensamble, que en si consiste en mejorar la precisión a través del uso de diferentes algoritmos.
En este post trabajare con dichos metódos a través de un ejemplo, pero a la par incluire un concepto estadístico que a mi pensar hace el combo perfecto para el desarrollo bajo está metodología, hablaré por lo tanto de VIF." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://danieljimenezm.com/post/2020-02-10-ensamble/" />

<meta itemprop="name" content="Un caso aplicado a los metódos de ensamble">
<meta itemprop="description" content="Metódos de ensamble Uno de los problemas al trabajar con machine learning consiste en optimizar el accuracy de los modelos y para ello una de las mejores vias es trabajar con modelos de ensamble, que en si consiste en mejorar la precisión a través del uso de diferentes algoritmos.
En este post trabajare con dichos metódos a través de un ejemplo, pero a la par incluire un concepto estadístico que a mi pensar hace el combo perfecto para el desarrollo bajo está metodología, hablaré por lo tanto de VIF.">

<meta itemprop="wordCount" content="2740">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Un caso aplicado a los metódos de ensamble"/>
<meta name="twitter:description" content="Metódos de ensamble Uno de los problemas al trabajar con machine learning consiste en optimizar el accuracy de los modelos y para ello una de las mejores vias es trabajar con modelos de ensamble, que en si consiste en mejorar la precisión a través del uso de diferentes algoritmos.
En este post trabajare con dichos metódos a través de un ejemplo, pero a la par incluire un concepto estadístico que a mi pensar hace el combo perfecto para el desarrollo bajo está metodología, hablaré por lo tanto de VIF."/>


    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    
</head>
<body>
    
<nav class="navbar navbar-expand-md navbar-light bg-light fixed-top shadow-sm" id="navbar-main-menu">
    <div class="container">
        <a class="navbar-brand font-weight-bold" href="https://danieljimenezm.com">Un Data Scientist Dice</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-menu" aria-controls="main-menu" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="main-menu">
            <ul class="navbar-nav ml-auto">
                
                    <li class="nav-item"><a class="nav-link" href="/">Home</a></li>
                
                    <li class="nav-item"><a class="nav-link" href="/about/">About</a></li>
                
            
            </ul>
        </div>
    </div>
</nav>


    
<main class="content-page container pt-7 pb-5">
    
    <div class="row">
        <div class="col">
            <article>
                <div class="row justify-content-center">
                    <div class="col-lg-8">
                        <div class="meta text-muted mb-3">
                            <p class="created text-muted text-uppercase font-weight-bold mb-1">January 1, 0001</p>
                            <span class="mr-2"><i class="fas fa-book-open mr-2"></i>2740 words</span>
                            <span><i class="fas fa-clock mr-2"></i>13 mins read</span>
                        </div>

                        <h1>Un caso aplicado a los metódos de ensamble</h1>

                        
                    </div>
                </div><div class="row justify-content-center">
                    <div class="col-lg-8">
                        <div class="content">
                            


<div id="metódos-de-ensamble" class="section level2">
<h2>Metódos de ensamble</h2>
<p>Uno de los problemas al trabajar con <code>machine learning</code> consiste en optimizar el <code>accuracy</code> de los modelos y para ello una de las mejores vias es trabajar con modelos de ensamble, que en si consiste en mejorar la precisión a través del uso de diferentes algoritmos.</p>
<p>En este post trabajare con dichos metódos a través de un ejemplo, pero a la par incluire un concepto estadístico que a mi pensar hace el combo perfecto para el desarrollo bajo está metodología, hablaré por lo tanto de <strong>VIF</strong>.</p>
</div>
<div id="conceptos-previsos" class="section level2">
<h2>Conceptos previsos</h2>
<p>Para hablar de metódos de ensamble es necesario aclarar varios algoritmos para trabajar , en el siguiente apartado trataré con los árboles de decisión.</p>
<div id="árboles-de-decisión" class="section level3">
<h3>Árboles de decisión</h3>
<p>Una definición acertada que se da desde el portal de <a href="https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052">towards data science</a> es la siguiente</p>
<blockquote>
<p>“A tree has many analogies in real life, and turns out that it has influenced a wide area of machine learning, covering both classification and regression. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. As the name goes, it uses a tree-like model of decisions.”</p>
</blockquote>
<p>Uno de los aspectos más importante para trabajar con este tipo de algoritmos es entender que el segmenta los espacios de los predictores en <span class="math inline">\(n\)</span> regiones a través del promedio o la mediana de los datos. Por lo tanto estás regiones tienden a ser independientes unas de otras y puede que sus dimensiones sean diferentes entre si , generando un <a href="https://www.statisticshowto.datasciencecentral.com/rmse/">rmse</a> lo suficientemente bajo, de la siguiente manera</p>
<p><span class="math display">\[
\sum_{j=1}^{J} \sum_{i \in R_{j}}(y_{i}-\hat{y_{R_j}})^2 \mbox{ Donde Y_jr}   \mbox{ es el promedio de la región respuesta de } J
\]</span></p>
<p>Más hay que tener en cuenta que al comienzo de cada árbol todos los datos empiezan en la misma región <span class="math inline">\(J\)</span> y en cada stepwise se divide en dos, buscando los mejores parámetros a través de una división recursiva.</p>
<p>Por lo tanto teniendo en cuenta las regiones y los predictores se generan los cortes a través de una minimización de la suma de los RSS</p>
<p><span class="math display">\[
\sum_{i:x_{i}\in R_{1}(a,j)} (y_{i}-\hat{y}_{r_i})^2+\sum_{i:x_{i}\in R_{2}(a,j)} (y_{i}-\hat{y}_{r_i})^2
\]</span></p>
<p>Para determinar el tamaño de estos árboles es necesario hacer una reducción de la varianza a través de arboles más pequeños (bias) con lo cual se mejora la capacidad de interpretación de los mismos y de paso así un menor error , pero esto a través de cost complexity pruning , en donde se selecciona un número de sub-árboles de interés.</p>
</div>
<div id="bagging" class="section level3">
<h3>Bagging</h3>
<p>Es una técnica creada por Leo Breiman (2005), que consiste Boostrap aggregation que permite estabilizar el accuracy de un modelo , gracias a que genera diferentes modelos gracias a que genera muestras aleatorias con reemplazo y luego para cada una de ellas busca el modelo más adecuado para resolver cada región de datos.</p>
<p>Por lo anterior, se puede reducir el tamaño de la varianza <span class="math inline">\(\sigma^2\)</span> promediando el tamaño de las observaciones a través de <span class="math inline">\((N_{(1,2,3,...,z)}/\sigma^2)^{-1}\)</span>, para asi después validar el modelo a travñes de boostrap con un <span class="math inline">\(n\)</span> del 67% de las observaciones. EL resto de los datos se les conoce como <em>out of bag</em> se usa para calcular nuevas predicciones.</p>
</div>
<div id="random-forest" class="section level3">
<h3>Random Forest</h3>
<p>Es un algoritmo de ML supervisado en donde se generan multiples árboles de decisiones en donde por cada una de sus ramificaciones suele trabajar con un predictor , lo cual reduce en gran medida la varianza y no genera un predictor único</p>
</div>
<div id="boosting" class="section level3">
<h3>Boosting</h3>
<p>Funciona igual que el bagging en el decision tree, pero en este caso cada nodo se construye con información residual , por lo cual su dimensión tiende a ser más pequeña.</p>
</div>
</div>
<div id="métodos-de-ensamble" class="section level2">
<h2>Métodos de ensamble</h2>
<p>En está sección se presentará un ejemplo de como generar ensambles , se trabajará con el set de datos de <code>nobels</code></p>
<table>
<caption><span id="tab:unnamed-chunk-2">Table 1: </span>Nobels Prize</caption>
<thead>
<tr class="header">
<th align="right">prize_year</th>
<th align="left">category</th>
<th align="left">prize</th>
<th align="left">motivation</th>
<th align="left">prize_share</th>
<th align="right">laureate_id</th>
<th align="left">laureate_type</th>
<th align="left">full_name</th>
<th align="left">birth_date</th>
<th align="left">birth_city</th>
<th align="left">birth_country</th>
<th align="left">gender</th>
<th align="left">organization_name</th>
<th align="left">organization_city</th>
<th align="left">organization_country</th>
<th align="left">death_date</th>
<th align="left">death_city</th>
<th align="left">death_country</th>
<th align="right">decade</th>
<th align="right">age</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1901</td>
<td align="left">Chemistry</td>
<td align="left">The Nobel Prize in Chemistry 1901</td>
<td align="left">“in recognition of the extraordinary services he has rendered by the discovery of the laws of chemical dynamics and osmotic pressure in solutions”</td>
<td align="left">1/1</td>
<td align="right">160</td>
<td align="left">Individual</td>
<td align="left">Jacobus Henricus van ’t Hoff</td>
<td align="left">1852-08-30</td>
<td align="left">Rotterdam</td>
<td align="left">Netherlands</td>
<td align="left">Male</td>
<td align="left">Berlin University</td>
<td align="left">Berlin</td>
<td align="left">Germany</td>
<td align="left">1911-03-01</td>
<td align="left">Berlin</td>
<td align="left">Germany</td>
<td align="right">1900</td>
<td align="right">49</td>
</tr>
<tr class="even">
<td align="right">1901</td>
<td align="left">Literature</td>
<td align="left">The Nobel Prize in Literature 1901</td>
<td align="left">“in special recognition of his poetic composition, which gives evidence of lofty idealism, artistic perfection and a rare combination of the qualities of both heart and intellect”</td>
<td align="left">1/1</td>
<td align="right">569</td>
<td align="left">Individual</td>
<td align="left">Sully Prudhomme</td>
<td align="left">1839-03-16</td>
<td align="left">Paris</td>
<td align="left">France</td>
<td align="left">Male</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">1907-09-07</td>
<td align="left">Châtenay</td>
<td align="left">France</td>
<td align="right">1900</td>
<td align="right">62</td>
</tr>
<tr class="odd">
<td align="right">1901</td>
<td align="left">Medicine</td>
<td align="left">The Nobel Prize in Physiology or Medicine 1901</td>
<td align="left">“for his work on serum therapy, especially its application against diphtheria, by which he has opened a new road in the domain of medical science and thereby placed in the hands of the physician a victorious weapon against illness and deaths”</td>
<td align="left">1/1</td>
<td align="right">293</td>
<td align="left">Individual</td>
<td align="left">Emil Adolf von Behring</td>
<td align="left">1854-03-15</td>
<td align="left">Hansdorf (Lawice)</td>
<td align="left">Prussia (Poland)</td>
<td align="left">Male</td>
<td align="left">Marburg University</td>
<td align="left">Marburg</td>
<td align="left">Germany</td>
<td align="left">1917-03-31</td>
<td align="left">Marburg</td>
<td align="left">Germany</td>
<td align="right">1900</td>
<td align="right">47</td>
</tr>
<tr class="even">
<td align="right">1901</td>
<td align="left">Peace</td>
<td align="left">The Nobel Peace Prize 1901</td>
<td align="left">NA</td>
<td align="left">1/2</td>
<td align="right">462</td>
<td align="left">Individual</td>
<td align="left">Jean Henry Dunant</td>
<td align="left">1828-05-08</td>
<td align="left">Geneva</td>
<td align="left">Switzerland</td>
<td align="left">Male</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">1910-10-30</td>
<td align="left">Heiden</td>
<td align="left">Switzerland</td>
<td align="right">1900</td>
<td align="right">73</td>
</tr>
<tr class="odd">
<td align="right">1901</td>
<td align="left">Peace</td>
<td align="left">The Nobel Peace Prize 1901</td>
<td align="left">NA</td>
<td align="left">1/2</td>
<td align="right">463</td>
<td align="left">Individual</td>
<td align="left">Frédéric Passy</td>
<td align="left">1822-05-20</td>
<td align="left">Paris</td>
<td align="left">France</td>
<td align="left">Male</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">1912-06-12</td>
<td align="left">Paris</td>
<td align="left">France</td>
<td align="right">1900</td>
<td align="right">79</td>
</tr>
<tr class="even">
<td align="right">1901</td>
<td align="left">Physics</td>
<td align="left">The Nobel Prize in Physics 1901</td>
<td align="left">“in recognition of the extraordinary services he has rendered by the discovery of the remarkable rays subsequently named after him”</td>
<td align="left">1/1</td>
<td align="right">1</td>
<td align="left">Individual</td>
<td align="left">Wilhelm Conrad Röntgen</td>
<td align="left">1845-03-27</td>
<td align="left">Lennep (Remscheid)</td>
<td align="left">Prussia (Germany)</td>
<td align="left">Male</td>
<td align="left">Munich University</td>
<td align="left">Munich</td>
<td align="left">Germany</td>
<td align="left">1923-02-10</td>
<td align="left">Munich</td>
<td align="left">Germany</td>
<td align="right">1900</td>
<td align="right">56</td>
</tr>
</tbody>
</table>
<p>Un poco de análisis exploratorio , en este paso se intentará describir el número de premios nobel por áreas.</p>
<p><img src="/post/2020-02-10-ensamble_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p><img src="/post/2020-02-10-ensamble_files/figure-html/unnamed-chunk-4-1.png" width="672" />
Ahora se evalua como es el comportamiento por pais y dada la categoría del nobel.</p>
<p><img src="/post/2020-02-10-ensamble_files/figure-html/unnamed-chunk-5-1.png" width="672" />
Se genera un featuring en donde se explora el tipo de pais a través de ingresos para asi clasificar por rangos el tipo de pasís (a nivel económico) y sus caracteristicas en los nobels</p>
<pre><code>## Warning: `tbl_df()` is deprecated as of dplyr 1.0.0.
## Please use `tibble::as_tibble()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<p>Featuring tomado de <a href="http://varianceexplained.org/about/">David Robinson</a>
<img src="/post/2020-02-10-ensamble_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code>nobel_winners_countries%&gt;%
  group_by(category)%&gt;%
  summarize(n=n())%&gt;%
  arrange(desc(n))%&gt;%
  mutate(category=fct_reorder(category,n))%&gt;%
  ggplot(aes(category,n,fill=category))+
  geom_bar(stat =&#39;identity&#39;)+
  labs(x=&#39;Categoría&#39;,y=&#39;Count&#39;,title = &#39;Relación de los premios por categoría&#39;)</code></pre>
<p><img src="/post/2020-02-10-ensamble_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Se crea la partición de los datos</p>
<pre class="r"><code>library(caret)</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## 
## Attaching package: &#39;caret&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     lift</code></pre>
<pre class="r"><code>nobel_winners_countries%&gt;%
  na.omit()-&gt;data
index&lt;-createDataPartition(data$category,times = 1,p = 0.8,list = FALSE)
train_set&lt;-data[index,]</code></pre>
<pre><code>## Warning: The `i` argument of ``[`()` can&#39;t be a matrix as of tibble 3.0.0.
## Convert to a vector.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<pre class="r"><code>test_set&lt;-data[-index,]</code></pre>
<pre class="r"><code>prop.table(table(train_set$category))*100</code></pre>
<pre><code>## 
## Chemistry Economics  Medicine   Physics 
## 26.845638  9.731544 35.234899 28.187919</code></pre>
<p>Hay que hacer una transformación antes de implementar el modelo, y es convertir a factor la variable <code>category</code></p>
<pre class="r"><code>test_set$category&lt;-as.factor(test_set$category)
train_set$prize&lt;-as.factor(train_set$prize)
train_set$gender&lt;-as.factor(train_set$gender)
test_set$category&lt;-as.factor(test_set$category)
test_set$prize&lt;-as.factor(test_set$prize)
test_set$gender&lt;-as.factor(test_set$gender)
train_set$category&lt;-as.factor(train_set$category)
train_set$laureate_type&lt;-as.factor(train_set$laureate_type)
test_set$laureate_type&lt;-as.factor(test_set$laureate_type)
# Training with classification tree
multiclass &lt;- rpart(category ~prize_year+age+gender+decade+income+gdp_per_capita+laureate_type, data=na.omit(train_set))
print(multiclass, digits = 3)</code></pre>
<pre><code>## n= 298 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 298 193 Medicine (0.26846 0.09732 0.35235 0.28188)  
##    2) age&gt;=61.5 107  71 Medicine (0.18692 0.26168 0.33645 0.21495)  
##      4) prize_year&gt;=1.95e+03 90  62 Economics (0.21111 0.31111 0.23333 0.24444)  
##        8) prize_year&lt; 1.97e+03 12   7 Chemistry (0.41667 0.00000 0.33333 0.25000) *
##        9) prize_year&gt;=1.97e+03 78  50 Economics (0.17949 0.35897 0.21795 0.24359)  
##         18) age&lt; 71.5 37  19 Economics (0.16216 0.48649 0.18919 0.16216)  
##           36) prize_year&gt;=1.97e+03 30  14 Economics (0.20000 0.53333 0.20000 0.06667) *
##           37) prize_year&lt; 1.97e+03 7   3 Physics (0.00000 0.28571 0.14286 0.57143) *
##         19) age&gt;=71.5 41  28 Physics (0.19512 0.24390 0.24390 0.31707) *
##      5) prize_year&lt; 1.95e+03 17   2 Medicine (0.05882 0.00000 0.88235 0.05882) *
##    3) age&lt; 61.5 191 122 Medicine (0.31414 0.00524 0.36126 0.31937)  
##      6) age&gt;=48.5 103  59 Medicine (0.33981 0.00971 0.42718 0.22330)  
##       12) prize_year&lt; 1.98e+03 91  49 Medicine (0.34066 0.01099 0.46154 0.18681)  
##         24) prize_year&lt; 1.93e+03 24  13 Chemistry (0.45833 0.00000 0.25000 0.29167)  
##           48) prize_year&gt;=1.92e+03 10   3 Chemistry (0.70000 0.00000 0.20000 0.10000) *
##           49) prize_year&lt; 1.92e+03 14   8 Physics (0.28571 0.00000 0.28571 0.42857) *
##         25) prize_year&gt;=1.93e+03 67  31 Medicine (0.29851 0.01493 0.53731 0.14925) *
##       13) prize_year&gt;=1.98e+03 12   6 Physics (0.33333 0.00000 0.16667 0.50000) *
##      7) age&lt; 48.5 88  50 Physics (0.28409 0.00000 0.28409 0.43182)  
##       14) prize_year&gt;=1.97e+03 7   2 Medicine (0.14286 0.00000 0.71429 0.14286) *
##       15) prize_year&lt; 1.97e+03 81  44 Physics (0.29630 0.00000 0.24691 0.45679) *</code></pre>
<pre class="r"><code>rpart.plot(multiclass)</code></pre>
<pre><code>## Warning: Bad &#39;data&#39; field in model &#39;call&#39; (expected a data.frame or a matrix).
## To silence this warning:
##     Call rpart.plot with roundint=FALSE,
##     or rebuild the rpart model with model=TRUE.</code></pre>
<p><img src="/post/2020-02-10-ensamble_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<pre class="r"><code>predictions1 &lt;- predict(multiclass, test_set, type = &quot;class&quot;)
confusionMatrix(predictions1, test_set$category)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##            Reference
## Prediction  Chemistry Economics Medicine Physics
##   Chemistry         4         0        1       4
##   Economics         4         3        4       2
##   Medicine          7         0       10       6
##   Physics           5         4       11       8
## 
## Overall Statistics
##                                           
##                Accuracy : 0.3425          
##                  95% CI : (0.2353, 0.4628)
##     No Information Rate : 0.3562          
##     P-Value [Acc &gt; NIR] : 0.63907         
##                                           
##                   Kappa : 0.1015          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.02231         
## 
## Statistics by Class:
## 
##                      Class: Chemistry Class: Economics Class: Medicine
## Sensitivity                   0.20000          0.42857          0.3846
## Specificity                   0.90566          0.84848          0.7234
## Pos Pred Value                0.44444          0.23077          0.4348
## Neg Pred Value                0.75000          0.93333          0.6800
## Prevalence                    0.27397          0.09589          0.3562
## Detection Rate                0.05479          0.04110          0.1370
## Detection Prevalence          0.12329          0.17808          0.3151
## Balanced Accuracy             0.55283          0.63853          0.5540
##                      Class: Physics
## Sensitivity                  0.4000
## Specificity                  0.6226
## Pos Pred Value               0.2857
## Neg Pred Value               0.7333
## Prevalence                   0.2740
## Detection Rate               0.1096
## Detection Prevalence         0.3836
## Balanced Accuracy            0.5113</code></pre>
<p>Ahora con el modelo de Randon Forest</p>
<pre class="r"><code>library(randomForest)
set.seed(12345)

rf_mc &lt;- randomForest(category ~prize_year+age+gender+decade+income+gdp_per_capita+laureate_type, data=na.omit(train_set))

# Predict the testing set with the trained model
predictions2 &lt;- predict(rf_mc, test_set, type = &quot;class&quot;)

# Accuracy and other metrics
confusionMatrix(predictions2, test_set$category)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##            Reference
## Prediction  Chemistry Economics Medicine Physics
##   Chemistry         2         0        2       7
##   Economics         4         2        5       2
##   Medicine         13         2       14       6
##   Physics           1         3        5       5
## 
## Overall Statistics
##                                           
##                Accuracy : 0.3151          
##                  95% CI : (0.2113, 0.4344)
##     No Information Rate : 0.3562          
##     P-Value [Acc &gt; NIR] : 0.802907        
##                                           
##                   Kappa : 0.0465          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.005884        
## 
## Statistics by Class:
## 
##                      Class: Chemistry Class: Economics Class: Medicine
## Sensitivity                    0.1000          0.28571          0.5385
## Specificity                    0.8302          0.83333          0.5532
## Pos Pred Value                 0.1818          0.15385          0.4000
## Neg Pred Value                 0.7097          0.91667          0.6842
## Prevalence                     0.2740          0.09589          0.3562
## Detection Rate                 0.0274          0.02740          0.1918
## Detection Prevalence           0.1507          0.17808          0.4795
## Balanced Accuracy              0.4651          0.55952          0.5458
##                      Class: Physics
## Sensitivity                 0.25000
## Specificity                 0.83019
## Pos Pred Value              0.35714
## Neg Pred Value              0.74576
## Prevalence                  0.27397
## Detection Rate              0.06849
## Detection Prevalence        0.19178
## Balanced Accuracy           0.54009</code></pre>
<p>Por el momento el árbol tiene mayor ventaja en el pronóstico</p>
<p>Con Bagging se encuentran los siguientes resultados</p>
<pre class="r"><code>seat_bag = randomForest(category ~prize_year+age+gender+decade+income+gdp_per_capita+laureate_type, data=na.omit(train_set), mtry = 6, importance = TRUE, ntrees = 50)
seat_bag</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = category ~ prize_year + age + gender +      decade + income + gdp_per_capita + laureate_type, data = na.omit(train_set),      mtry = 6, importance = TRUE, ntrees = 50) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 6
## 
##         OOB estimate of  error rate: 66.78%
## Confusion matrix:
##           Chemistry Economics Medicine Physics class.error
## Chemistry        18         7       27      28   0.7750000
## Economics         7         5        8       9   0.8275862
## Medicine         21         9       55      20   0.4761905
## Physics          26        10       27      21   0.7500000</code></pre>
<pre class="r"><code>predictions3 &lt;- predict(seat_bag, test_set, type = &quot;class&quot;)

# Accuracy and other metrics
confusionMatrix(predictions3, test_set$category)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##            Reference
## Prediction  Chemistry Economics Medicine Physics
##   Chemistry         6         0        5       7
##   Economics         2         2        4       2
##   Medicine          9         2       11       7
##   Physics           3         3        6       4
## 
## Overall Statistics
##                                           
##                Accuracy : 0.3151          
##                  95% CI : (0.2113, 0.4344)
##     No Information Rate : 0.3562          
##     P-Value [Acc &gt; NIR] : 0.8029          
##                                           
##                   Kappa : 0.0458          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.4592          
## 
## Statistics by Class:
## 
##                      Class: Chemistry Class: Economics Class: Medicine
## Sensitivity                   0.30000          0.28571          0.4231
## Specificity                   0.77358          0.87879          0.6170
## Pos Pred Value                0.33333          0.20000          0.3793
## Neg Pred Value                0.74545          0.92063          0.6591
## Prevalence                    0.27397          0.09589          0.3562
## Detection Rate                0.08219          0.02740          0.1507
## Detection Prevalence          0.24658          0.13699          0.3973
## Balanced Accuracy             0.53679          0.58225          0.5200
##                      Class: Physics
## Sensitivity                 0.20000
## Specificity                 0.77358
## Pos Pred Value              0.25000
## Neg Pred Value              0.71930
## Prevalence                  0.27397
## Detection Rate              0.05479
## Detection Prevalence        0.21918
## Balanced Accuracy           0.48679</code></pre>
<p>La importancia de las variables acá es la siguiente</p>
<pre class="r"><code>varImpPlot(seat_bag)</code></pre>
<p><img src="/post/2020-02-10-ensamble_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>Por lo pronto se baja o poda el número de ramifiaciones para poder optimizar los parámetros</p>
<pre class="r"><code>oob = trainControl(method = &quot;oob&quot;)
cv_10 = trainControl(method = &quot;cv&quot;, number = 6)
rf_grid =  expand.grid(mtry = 1:6)</code></pre>
<pre class="r"><code>set.seed(825)
seat_rf_tune = train(category ~prize_year+age+gender+decade+income+gdp_per_capita, data=na.omit(train_set),
                     method = &quot;rf&quot;,
                     trControl = oob,
                     verbose = FALSE,
                     tuneGrid = rf_grid)
seat_rf_tune</code></pre>
<pre><code>## Random Forest 
## 
## 298 samples
##   6 predictor
##   4 classes: &#39;Chemistry&#39;, &#39;Economics&#39;, &#39;Medicine&#39;, &#39;Physics&#39; 
## 
## No pre-processing
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa      
##   1     0.3322148  -0.02575545
##   2     0.3187919   0.01835294
##   3     0.3456376   0.07716495
##   4     0.3557047   0.09938612
##   5     0.3657718   0.11765259
##   6     0.3691275   0.11945178
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 6.</code></pre>
<p>Se identifico que el mejor modelo es con <code>mtry=3</code>, y su capacidad de pronóstico es la siguiente</p>
<pre class="r"><code>seat_bag_tst_pred = predict(seat_bag, newdata = test_set)
confusionMatrix(seat_bag_tst_pred, test_set$category)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##            Reference
## Prediction  Chemistry Economics Medicine Physics
##   Chemistry         6         0        5       7
##   Economics         2         2        4       2
##   Medicine          9         2       12       7
##   Physics           3         3        5       4
## 
## Overall Statistics
##                                           
##                Accuracy : 0.3288          
##                  95% CI : (0.2233, 0.4487)
##     No Information Rate : 0.3562          
##     P-Value [Acc &gt; NIR] : 0.7268          
##                                           
##                   Kappa : 0.0634          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.4296          
## 
## Statistics by Class:
## 
##                      Class: Chemistry Class: Economics Class: Medicine
## Sensitivity                   0.30000          0.28571          0.4615
## Specificity                   0.77358          0.87879          0.6170
## Pos Pred Value                0.33333          0.20000          0.4000
## Neg Pred Value                0.74545          0.92063          0.6744
## Prevalence                    0.27397          0.09589          0.3562
## Detection Rate                0.08219          0.02740          0.1644
## Detection Prevalence          0.24658          0.13699          0.4110
## Balanced Accuracy             0.53679          0.58225          0.5393
##                      Class: Physics
## Sensitivity                 0.20000
## Specificity                 0.79245
## Pos Pred Value              0.26667
## Neg Pred Value              0.72414
## Prevalence                  0.27397
## Detection Rate              0.05479
## Detection Prevalence        0.20548
## Balanced Accuracy           0.49623</code></pre>
<pre class="r"><code>calc_acc = function(actual, predicted) {
  mean(actual == predicted)
}
(bag_tst_acc = calc_acc(predicted = seat_bag_tst_pred, actual = test_set$category))</code></pre>
<pre><code>## [1] 0.3287671</code></pre>
<p>Con boosting los resultados son los siguientes</p>
<pre class="r"><code>seat_boost = gbm(category ~prize_year+age+gender+decade+income+gdp_per_capita+laureate_type, data=na.omit(train_set), distribution = &quot;tdist&quot;, 
                 n.trees = 5000, interaction.depth = 4, shrinkage = 0.01)</code></pre>
<pre><code>## Warning in gbm.fit(x = x, y = y, offset = offset, distribution = distribution, :
## variable 7: laureate_type has no variation.</code></pre>
<pre class="r"><code>seat_boost</code></pre>
<pre><code>## gbm(formula = category ~ prize_year + age + gender + decade + 
##     income + gdp_per_capita + laureate_type, distribution = &quot;tdist&quot;, 
##     data = na.omit(train_set), n.trees = 5000, interaction.depth = 4, 
##     shrinkage = 0.01)
## A gradient boosted model with tdist loss function.
## 5000 iterations were performed.
## There were 7 predictors of which 4 had non-zero influence.</code></pre>
<pre class="r"><code>seat_boost_tst_pred = predict(seat_boost, test_set, n.trees = 50)
(boost_tst_acc = calc_acc(predicted = seat_boost_tst_pred, actual = test_set$category))</code></pre>
<pre><code>## [1] 0</code></pre>
<p>Por lo tanto la selección del modelo será la siguiente</p>
<pre class="r"><code>(seat_acc = data.frame(
  Model = c(&quot;Single Tree&quot;, &quot;Random Forest&quot;,  &quot;Bagging&quot;, &quot;Boosting&quot;),
  TestAccuracy = c(confusionMatrix(predictions1, test_set$category)$overall[1],confusionMatrix(predictions2, test_set$category)$overall[1],confusionMatrix(predictions3, test_set$category)$overall[1],boost_tst_acc)
  )
)</code></pre>
<pre><code>##           Model TestAccuracy
## 1   Single Tree    0.3424658
## 2 Random Forest    0.3150685
## 3       Bagging    0.3150685
## 4      Boosting    0.0000000</code></pre>
<pre class="r"><code>seat_acc%&gt;%
  ggplot(aes(reorder(Model,TestAccuracy),TestAccuracy, fill=Model))+
  geom_col(show.legend = FALSE)+
  coord_flip()+
  labs(x=&quot;models&quot;,y=&quot;Test Accuracy&quot;)</code></pre>
<p><img src="/post/2020-02-10-ensamble_files/figure-html/unnamed-chunk-26-1.png" width="672" />
EL modelo que mejor predice es el del árbol de decision, y por lo tanto este deberá ser el seleccionado para este trabajo</p>
</div>
<div id="bibliografía" class="section level2">
<h2>Bibliografía</h2>
<ul>
<li><p><a href="https://daviddalpiaz.github.io/r4sl/ensemble-methods.html#classification-2" class="uri">https://daviddalpiaz.github.io/r4sl/ensemble-methods.html#classification-2</a></p></li>
<li><p><a href="https://rpubs.com/Cristina_Gil/arboles_ensemble" class="uri">https://rpubs.com/Cristina_Gil/arboles_ensemble</a></p></li>
<li><p><a href="https://moderndive.com/10-inference-for-regression.html" class="uri">https://moderndive.com/10-inference-for-regression.html</a></p></li>
</ul>
</div>

                        </div><ul class="share nav my-3 justify-content-end">
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://twitter.com/intent/tweet?url=https%3a%2f%2fdanieljimenezm.com%2fpost%2f2020-02-10-ensamble%2f&text=Un%20caso%20aplicado%20a%20los%20met%c3%b3dos%20de%20ensamble">
              <i class="fa-fw fab fa-twitter"></i>
          </a>
        </li>
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fdanieljimenezm.com%2fpost%2f2020-02-10-ensamble%2f&title=Un%20caso%20aplicado%20a%20los%20met%c3%b3dos%20de%20ensamble">
                <i class="fa-fw fab fa-linkedin-in"></i>
            </a>
        </li>
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fdanieljimenezm.com%2fpost%2f2020-02-10-ensamble%2f&t=Un%20caso%20aplicado%20a%20los%20met%c3%b3dos%20de%20ensamble">
                <i class="fa-fw fab fa-facebook-f"></i>
            </a>
        </li>
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://reddit.com/submit?url=https%3a%2f%2fdanieljimenezm.com%2fpost%2f2020-02-10-ensamble%2f&title=Un%20caso%20aplicado%20a%20los%20met%c3%b3dos%20de%20ensamble">
                <i class="fa-fw fab fa-reddit-alien"></i>
            </a>
        </li>
    </nav>
                    </div>
                </div>

                <div class="row justify-content-center">
                    <div class="col-lg-8">
                        
                    </div>
                </div><div class="row justify-content-center my-3">
                    <div class="col-lg-8">
                        <div id="commento"></div>
                        <script src="https://commento.io"></script>
                    </div>
                </div></article>
        </div>
    </div>

    
</main>


    <footer class="footer text-center bg-dark py-6">
    <div class="container">
        <div class="row">
            <div class="col">
                <ul class="list-inline">
                    <li class="list-inline-item"><a href="https://danieljimenezm.com/index.xml" rel="alternate" type="application/rss+xml" class="icons d-block">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a></li><li class="list-inline-item">
                        <a href="mailto:cjimenez187@aol.com" class="icons d-block">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li><li class="list-inline-item">
                            <a href="https://github.com/carlosjimenez88M" class="icons d-block">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li><li class="list-inline-item">
                            <a href="https://www.linkedin.com/in/djimenezm/" class="icons d-block">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li><li class="list-inline-item">
                            <a href="https://twitter.com/DanielJimenezM9" class="icons d-block">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                </ul>

                <p class="text-muted">
                    
                        Copyright © 2020, Daniel Jiménez; all rights reserved.
                    
                </p>

                <p class="text-muted">
                Powered by <a href="https://gohugo.io" target="_blank">Hugo</a> with <a href="https://github.com/puresyntax71/hugo-theme-chunky-poster" target="_blank">Chunky Poster</a>.
                </p>
            </div>
        </div>
    </div>
</footer>

    
    
        
            <script src="/dist/main.d608eadfe5ac0688902e.min.js"></script>
        
    



<script>
    window.Prism = window.Prism || {};
    window.Prism.manual = true;
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-core.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/plugins/autoloader/prism-autoloader.min.js"></script>






    
</body>
</html>
