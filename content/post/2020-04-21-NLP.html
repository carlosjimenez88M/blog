---
title: 'tidytuesday #17'
output: html_document
---



<div id="tidytuesday-17" class="section level2">
<h2>Tidytuesday #17</h2>
<p>En está oportunidad trabajaré una seríe de modelos en dos vías, lo cual fue un reto en el sentido del proceso, que se trabajo un NLP para la confirmación de otro, en la generación de targets.</p>
<p>Las base de datos que trabaje en está oportunidad son las siguientes:</p>
<p>Y el diccionario se encuentra en el siguiente link <code>https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-04-21/readme.md</code>.</p>
<p>Ahora si, manos a la obra, mostraré las librerias con las cuales se puede desarrollar el ejercicio</p>
<pre class="r"><code>library(tidyverse)
library(tidymodels)
library(moderndive)
library(lubridate)
library(mrgsolve)
library(tidytable)
library(stringr)
library(tidytext)
library(janeaustenr)
library(tidyr)
library(tm)
library(tidytext)
library(factoextra)
library(FactoMineR)</code></pre>
</div>
<div id="explorar-la-data" class="section level2">
<h2>Explorar la data</h2>
<p>Lo primero es ver como es el comportamiento criminal por país entre los años 2019 y 2020. EL resultado se imprime en pantalla</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Es interesante ver el comportamiento de España, pues tiene una tasa sostenida entre los años evaluados.</p>
<pre><code>## Selecting by n</code></pre>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>A nivel de variedad de delitos, España almacena la mayor variedad. Casos interesantes estan entre Rumania e Italia.</p>
<p>Ahora trabajaré un análisis de multicorrespondencia para entender que tanta relación hay entre los delitos y los países.</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Parece ser que hay 3 vectores propios que almacenan una gran cantidad de información para la definición que se busca y la construcción de las relaciones.</p>
<p>La relación entre paises y los delitos tiene una correspondencia interesante de apreciar.</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Una forma de evaluar este aprendizaje es a través del gradiente.</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>El anteiror gráfico muestra que hay una fuerte relación entre los pocos países y un tipo de delito especifico.</p>
<p>Ahora estudiaré la contribución de los datos a construir un concepto</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>La contribución es muy parecida a la del MCA. Un análisis individual de los casos vs país tiene un nivel de interpretación mucho más profundo.</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Voy a mirar el Caso de España que me llamo la atención</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Indudablemente acá hay un material único para trabajar. Veamos como es el comportamiento del delito a través de los años y el costo de los mismos.</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Esto es oro puro!!! Acá hay una cantidad de relaciones importantes.</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Acá estan los delitos relacionados y explicados por el país. Ahora intentaré entender cuales son los más relacionados y de mayor correspondencia individual.</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Y ahora la contribución del desarrollo de uno con respecto a otro.</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Interesante que el que más aporta es la no cooperación. Esto sería pertinente para un análisis sociologico.</p>
</div>
<div id="nlp" class="section level2">
<h2>NLP</h2>
<p>En está parte seguiré solo con el caso de España, por curiosidad a los resultados. En está parte trabajaré en el diseño de <code>targets</code> lo cual facilitará el trabajo de construir un modelo.</p>
<p>Con un análisis de bigrams podré entender como crear unos targets después de verficar los patrones.</p>
<pre><code>## # A tibble: 26 x 2
##    bigram               n
##  * &lt;chr&gt;            &lt;int&gt;
##  1 non compliance       3
##  2 basis for            2
##  3 compliance with      2
##  4 data processing      2
##  5 failure to           2
##  6 for data             2
##  7 lawful basis         2
##  8 with lawful          2
##  9 cooperate with       1
## 10 cooperation with     1
## # … with 16 more rows</code></pre>
<p>Notesé que las palabas acá señaladas tienen ya forma de un target.</p>
<pre><code>## # A tibble: 6 x 3
##    line word1      word2     
##   &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;     
## 1     1 non        compliance
## 2     1 compliance with      
## 3     1 with       lawful    
## 4     1 lawful     basis     
## 5     1 basis      for       
## 6     1 for        data</code></pre>
<p>Más falta un poco de trabajo estadístico sobre este modelo. Lo primero a desarrollar es la unión entre las palabras.</p>
<pre><code>## # A tibble: 35 x 2
##     line bigram         
##    &lt;int&gt; &lt;chr&gt;          
##  1     1 non compliance 
##  2     1 compliance with
##  3     1 with lawful    
##  4     1 lawful basis   
##  5     1 basis for      
##  6     1 for data       
##  7     1 data processing
##  8     2 failure to     
##  9     2 to cooperate   
## 10     2 cooperate with 
## # … with 25 more rows</code></pre>
<p>Paso seguido un análisis de frecuencia y correlación</p>
<pre class="r"><code>grams_tf_idf &lt;- grams_united %&gt;%
  count(line, bigram) %&gt;%
  bind_tf_idf(bigram, line, n) %&gt;%
  arrange(desc(tf_idf))

grams_tf_idf%&gt;%
  head()</code></pre>
<pre><code>## # A tibble: 6 x 6
##    line bigram                     n    tf   idf tf_idf
##   &lt;int&gt; &lt;chr&gt;                  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1     5 information obligation     1 0.333  1.79  0.597
## 2     5 obligation non             1 0.333  1.79  0.597
## 3     2 cooperate with             1 0.2    1.79  0.358
## 4     2 supervisory authority      1 0.2    1.79  0.358
## 5     2 to cooperate               1 0.2    1.79  0.358
## 6     2 with supervisory           1 0.2    1.79  0.358</code></pre>
<p>Ya va adquiriendo mejor forma y mayor realidad los datos. Ahora un pequeño análisis de construcción de sentido.</p>
<pre><code>## 
## Attaching package: &#39;igraph&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:mrgsolve&#39;:
## 
##     blocks</code></pre>
<pre><code>## The following objects are masked from &#39;package:lubridate&#39;:
## 
##     %--%, union</code></pre>
<pre><code>## The following objects are masked from &#39;package:dials&#39;:
## 
##     degree, neighbors</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     as_data_frame, groups, union</code></pre>
<pre><code>## The following objects are masked from &#39;package:purrr&#39;:
## 
##     compose, simplify</code></pre>
<pre><code>## The following object is masked from &#39;package:tidyr&#39;:
## 
##     crossing</code></pre>
<pre><code>## The following object is masked from &#39;package:tibble&#39;:
## 
##     as_data_frame</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     decompose, spectrum</code></pre>
<pre><code>## The following object is masked from &#39;package:base&#39;:
## 
##     union</code></pre>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Se crea una matriz de palabras y se verifica sus distancias .</p>
<pre><code>## Joining, by = &quot;word&quot;</code></pre>
<pre><code>## &lt;&lt;DocumentTermMatrix (documents: 6, terms: 18)&gt;&gt;
## Non-/sparse entries: 28/80
## Sparsity           : 74%
## Maximal term length: 11
## Weighting          : term frequency (tf)</code></pre>
<p>Paso seguido un análisis lineal discriminado, en el cual lo importante es ver el comportamiento de beta.</p>
<pre><code>## Warning: `tbl_df()` is deprecated as of dplyr 1.0.0.
## Please use `tibble::as_tibble()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<pre><code>## # A tibble: 20 x 3
##    topic term          beta
##    &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;
##  1     1 basis      0.0687 
##  2     2 basis      0.0627 
##  3     3 basis      0.0940 
##  4     4 basis      0.147  
##  5     5 basis      0.00179
##  6     6 basis      0.0543 
##  7     1 compliance 0.0634 
##  8     2 compliance 0.0609 
##  9     3 compliance 0.239  
## 10     4 compliance 0.160  
## 11     5 compliance 0.00704
## 12     6 compliance 0.114  
## 13     1 data       0.122  
## 14     2 data       0.00593
## 15     3 data       0.0726 
## 16     4 data       0.235  
## 17     5 data       0.00987
## 18     6 data       0.199  
## 19     1 lawful     0.0294 
## 20     2 lawful     0.0252</code></pre>
<p>Ahora se generan los topics, los cuales serán la semilla del target</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>Estos topics estan interesantes. Ahora un análisis con una matriz gamma para generar clasificaciones.</p>
<pre><code>## # A tibble: 6 x 3
##   document topic gamma
##   &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;
## 1 6            1 0.172
## 2 4            2 0.175
## 3 5            2 0.169
## 4 1            4 0.171
## 5 3            4 0.171
## 6 2            5 0.170</code></pre>
<p>Parece ser que ya se tienen los tipics por articulo. Para validar el supuesto un análisis gráfico ayuda bastante</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Quiero validar el nivel de certidumbre sobre lo que estoy haciendo</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>Las distribuciones de probabilidades dan seña que el trabajo va por buen camino. Ahora un camino más espinoso, generar el target y eliminar la inceritdumbre.</p>
<pre><code>## # A tibble: 28 x 4
##    document term       count .topic
##  * &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;
##  1 1        basis          1      4
##  2 3        basis          1      4
##  3 1        compliance     1      3
##  4 3        compliance     1      3
##  5 5        compliance     1      3
##  6 1        data           1      4
##  7 3        data           1      4
##  8 6        data           1      4
##  9 1        lawful         1      4
## 10 3        lawful         1      4
## # … with 18 more rows</code></pre>
<p>El paso más importante es eliminar la incertidumbre y para ello se realiza el siguiente proceso: <strong>Las palabras que contradigan al documento versus la ley seran expulsadas.</strong></p>
<pre><code>## # A tibble: 102 x 4
##    document topic gamma word      
##       &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;     
##  1        4     4 0.161 &lt;NA&gt;      
##  2        4     1 0.161 &lt;NA&gt;      
##  3        1     5 0.162 &lt;NA&gt;      
##  4        3     5 0.162 &lt;NA&gt;      
##  5        4     6 0.163 &lt;NA&gt;      
##  6        6     2 0.163 compliance
##  7        6     2 0.163 lawful    
##  8        6     2 0.163 basis     
##  9        6     2 0.163 data      
## 10        6     2 0.163 processing
## # … with 92 more rows</code></pre>
<pre><code>## # A tibble: 6 x 3
##   document topic gamma
##   &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;
## 1 6            1 0.172
## 2 4            2 0.175
## 3 5            2 0.169
## 4 1            4 0.171
## 5 3            4 0.171
## 6 2            5 0.170</code></pre>
<pre><code>## # A tibble: 6 x 2
##   topic     n
## * &lt;int&gt; &lt;int&gt;
## 1     1     6
## 2     2     6
## 3     3     6
## 4     4     6
## 5     5     6
## 6     6     6</code></pre>
<p>Los targets estan completos</p>
<p><img src="/post/2020-04-21-NLP_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<pre><code>##   topic                           category
## 1     1 cooperation,protection,supervisory
## 2     4                         protection
## 3     5                        supervisory
## 4     6             protection,cooperation</code></pre>
<p>Con esto termino el <code>tidytuesday</code>, espero que les guste.</p>
</div>
