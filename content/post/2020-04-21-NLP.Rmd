---
title: 'tidytuesday #17'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



## Tidytuesday #17

En está oportunidad trabajaré una seríe de modelos en dos vías, lo cual fue un reto en el sentido del proceso, que se trabajo un NLP para la confirmación de otro, en la generación de targets.

Las base de datos que trabaje en está oportunidad son las siguientes:

```{r eval=FALSE, include=FALSE}
gdpr_violations <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-21/gdpr_violations.tsv')
gdpr_text <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-21/gdpr_text.tsv')
```


Y el diccionario se encuentra en el siguiente link `https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-04-21/readme.md`.


Ahora si, manos a la obra, mostraré las librerias con las cuales se puede desarrollar el ejercicio 


```{r,warning=FALSE, message=FALSE}
library(tidyverse)
library(tidymodels)
library(moderndive)
library(lubridate)
library(mrgsolve)
library(tidytable)
library(stringr)
library(tidytext)
library(janeaustenr)
library(tidyr)
library(tm)
library(tidytext)
library(factoextra)
library(FactoMineR)
```




```{r, echo=FALSE,warning=FALSE,message=FALSE}
gdpr_violations <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-21/gdpr_violations.tsv')
gdpr_text <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-21/gdpr_text.tsv')
```


## Explorar la data

Lo primero es ver como es el comportamiento criminal por país entre los años 2019 y 2020. EL resultado se imprime en pantalla

```{r, echo=FALSE, cache=FALSE}
gdpr_violations%>%
  mutate(date=mdy(date))%>%
  mutate(year=year(date))%>%
  filter(year>=2019)%>%
  group_by(year,name,controller)%>%
  summarize(total=n())%>%
  ungroup()%>%
  group_by(year,name)%>%
  summarize(total=sum(total))%>%
  mutate(year=as.factor(year),
         name=reorder_within(name,total,year))%>%
  ggplot(aes(name,total, fill=name))+
  geom_col(show.legend = FALSE)+
  facet_wrap(~year,scales = "free_y")+
  scale_x_reordered() +
  scale_y_continuous(expand = c(0,0))+ 
  coord_flip()
```

Es interesante ver el comportamiento de España, pues tiene una tasa sostenida entre los años evaluados.


```{r, echo=FALSE, cache=FALSE}
top_controller<-gdpr_violations%>%
  mutate(date=mdy(date))%>%
  mutate(year=year(date))%>%
  filter(year!=1970)%>%
  group_by(year,name)%>%
  count(controller,sort = TRUE)%>%
  ungroup()
top_controller%>%
  filter(year>=2019)%>%
  filter(!str_detect(controller,"pdf"))%>%
  group_by(controller)%>%
  top_n(10)%>%
  ungroup()%>%
  mutate(year=factor(year),
         name=reorder_within(name,n,year)
         )%>%
  ggplot(aes(name,n,fill=controller))+
  geom_col(show.legend = FALSE)+
  facet_wrap(~year,scales="free_y")+
  scale_x_reordered() +
  scale_y_continuous(expand = c(0,0))+
  theme(legend.position="bottom")+
  coord_flip()
```

A nivel de variedad de delitos, España almacena la mayor variedad. Casos interesantes estan entre Rumania e Italia.


Ahora trabajaré un análisis de multicorrespondencia para entender que tanta relación hay entre los delitos y los países.

```{r, echo=FALSE, cache=FALSE}
categorical_delites<-gdpr_violations[,c(3,9)]

res.mca<-MCA(categorical_delites, graph = FALSE)
eig.val <- get_eigenvalue(res.mca)
fviz_screeplot(res.mca, addlabels = TRUE)
```

Parece ser que hay 3 vectores propios que almacenan una gran cantidad de información para la definición que se busca y la construcción de las  relaciones.


La relación entre paises y los delitos tiene una correspondencia interesante de apreciar.


```{r, echo=FALSE, cache=FALSE}
fviz_mca_var(res.mca, col.var="black", shape.var = 15,
             repel = TRUE)
```

Una forma de evaluar este aprendizaje es a través del gradiente.

```{r, echo=FALSE, cache=FALSE}
fviz_mca_var(res.mca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE, # Avoid text overlapping
             ggtheme = theme_minimal())
```


El anteiror gráfico muestra que hay una fuerte relación entre los pocos países y un tipo de delito especifico.

Ahora estudiaré la contribución de los datos a construir un concepto


```{r, echo=FALSE, cache=FALSE}
fviz_mca_var(res.mca, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE, # avoid text overlapping (slow)
             ggtheme = theme_minimal()
             )
```

La contribución es muy parecida a la del MCA. Un análisis individual de los casos  vs país tiene un nivel de interpretación mucho más profundo.


```{r, echo=FALSE, cache=FALSE}
ind <- get_mca_ind(res.mca)
fviz_mca_ind(res.mca, col.ind = "cos2", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, # Avoid text overlapping (slow if many points)
             ggtheme = theme_minimal())
```


```{r, echo=FALSE, cache=FALSE}
fviz_cos2(res.mca, choice = "ind", axes = 1:2, top = 8)
```

Voy a mirar el Caso de España que me llamo la atención


```{r, echo=FALSE, cache=FALSE, message=FALSE, warning=FALSE}
categorical_delites<-gdpr_violations[,c(3,9)]%>%
  filter(name=="Spain")

res.mca<-MCA(categorical_delites, graph = FALSE)
fviz_mca_ind(res.mca, habillage = 2, addEllipses = TRUE)
```


Indudablemente acá hay un material único para trabajar. Veamos como es el comportamiento del delito a través de los años y el costo de los mismos.


```{r, echo=FALSE, cache=FALSE}
gdpr_violations%>%
  filter(name=="Spain")%>%
  mutate(date=mdy(date))%>%
  mutate(year=year(date))%>%
  filter(year>=2019)%>%
  group_by(year,article_violated)%>%
  summarize(total=sum(price))%>%
  arrange(desc(total))%>%
  ggplot(aes(article_violated,total, fill=year))+
  geom_col(show.legend = FALSE)+
  coord_flip()+
  facet_wrap(~year,scales = "free")
```

Esto es oro puro!!! Acá hay una cantidad de relaciones importantes.


```{r, echo=FALSE, cache=FALSE}
eig.val <- get_eigenvalue(res.mca)
fviz_mca_var(res.mca, 
             repel = TRUE, # Avoid text overlapping (slow)
             ggtheme = theme_minimal())

```


Acá estan los delitos relacionados y explicados por el país. Ahora intentaré entender cuales son los más relacionados y de mayor correspondencia individual.


```{r, echo=FALSE, cache=FALSE}
fviz_mca_var(res.mca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE, # Avoid text overlapping
             ggtheme = theme_minimal())
```


Y ahora la contribución del desarrollo de uno con respecto a otro.

```{r, echo=FALSE, cache=FALSE}
fviz_mca_var(res.mca, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE, # avoid text overlapping (slow)
             ggtheme = theme_minimal()
             )
```

Interesante que el que más aporta es la no cooperación. Esto sería pertinente para un análisis sociologico. 

## NLP

En está parte seguiré solo con el caso de España, por curiosidad a los resultados. En está parte trabajaré en el diseño de `targets` lo cual facilitará el trabajo de construir un modelo.

Con un análisis de bigrams podré entender como crear unos targets después de verficar los patrones.

```{r, echo=FALSE, cache=FALSE,warning=FALSE,message=FALSE}
library(stringi)
regexp <- "[[:digit:]]+"
gdpr_violations%>%
  filter(name=="Spain")%>%
  mutate(date=mdy(date))%>%
  mutate(year=year(date))->gdpr_violations


gdpr_violations%>%
  separate(article_violated,into = c("art","art1"),sep = "\\|")%>%
  mutate(art_principal=as.numeric(str_extract(art,regexp)))%>%
  select(-c(art1,art))->violations

violations_art<-violations%>%
  select(art_principal,type)%>%
  distinct(art_principal,.keep_all = TRUE)

text_df<-violations_art%>%
  tibble(line=1:6,text=type)%>%
  select(c(line,text))

data("stop_words")
tidy_art<-text_df%>%
  unnest_tokens(word,text)%>%
  anti_join(stop_words)



article_bigram<-text_df%>%
  unnest_tokens(bigram,text,token = "ngrams",n=2)

article_bigram%>%
  count(bigram,sort=TRUE)




```


Notesé que las palabas acá señaladas tienen ya forma de un target.

```{r, echo=FALSE, cache=FALSE}
grams_separated <- article_bigram %>%
  separate(bigram, c("word1", "word2"), sep = " ")


grams_filtered<-grams_separated%>%
  filter(!word1 %in% stop_words)%>%
  filter(!word2 %in% stop_words)
grams_filtered%>%
  head()
```

Más falta un poco de trabajo estadístico sobre este modelo. Lo primero a desarrollar es la unión entre las palabras.


```{r, echo=FALSE, cache=FALSE}
grams_counts<-grams_filtered%>%
  count(word1,word2, sort = TRUE)

grams_united<-grams_filtered%>%
  unite(bigram,word1,word2,sep =" ")

grams_united
```


Paso seguido un análisis de frecuencia y correlación
```{r}
grams_tf_idf <- grams_united %>%
  count(line, bigram) %>%
  bind_tf_idf(bigram, line, n) %>%
  arrange(desc(tf_idf))

grams_tf_idf%>%
  head()
```

Ya va adquiriendo mejor forma y mayor realidad los datos. Ahora un pequeño análisis de construcción de sentido.


```{r, echo=FALSE, cache=FALSE}
library(igraph)
gram_graph <- grams_counts %>%
  graph_from_data_frame()

library(ggraph)
ggraph(gram_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)
```

Se crea una matriz de palabras y se verifica sus distancias .

```{r, echo=FALSE, cache=FALSE}
article_dtm<-text_df%>%
  unnest_tokens(word,text)%>%
  anti_join(stop_words)%>%
  count(line,word)%>%
  cast_dtm(line,word,n)

article_dtm
```

Paso seguido un análisis lineal discriminado, en el cual lo importante es ver el comportamiento de beta.

```{r, echo=FALSE, cache=FALSE}
library(tidyr)
library(janeaustenr)
library(topicmodels)


ap_lda <- LDA(article_dtm, k = 6, control = list(seed = 1234))
ap_topic<-tidy(ap_lda,matrix="beta")
ap_topic%>%
  head(20)
```

Ahora se generan los topics, los cuales serán la semilla del target


```{r, echo=FALSE, cache=FALSE}
ap_top_terms <- ap_topic %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

ap_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()
```


Estos topics estan interesantes. Ahora un análisis con una matriz gamma para generar clasificaciones.

```{r, echo=FALSE, cache=FALSE}
article_gamma <- tidy(ap_lda, matrix = "gamma")
article_classifications <- article_gamma %>%
  group_by(document) %>%
  top_n(1, gamma) %>%
  ungroup()

article_classifications
```

Parece ser que ya se tienen los tipics por articulo. Para validar el supuesto un análisis gráfico ayuda bastante

```{r, echo=FALSE, cache=FALSE}
article_gamma %>%
  mutate(title = reorder(document, gamma * topic)) %>%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot() +
  facet_wrap(~document)

```


Quiero validar el nivel de certidumbre sobre lo que estoy haciendo

```{r, echo=FALSE, cache=FALSE}
ggplot(article_gamma, aes(gamma, fill = as.factor(topic))) +
  geom_histogram(show.legend = FALSE, bins = 5) +
  facet_wrap(~ topic, ncol = 4) +
  #scale_y_log10() +
  labs(title = "Distribution of probability for each topic",
       y = "Number of documents", x = expression(gamma))
```

Las distribuciones de probabilidades dan seña que el trabajo va por buen camino. Ahora un camino más espinoso, generar el target y eliminar la inceritdumbre.


```{r, echo=FALSE, cache=FALSE}
article_topics <- article_classifications %>%
  count(document, topic) %>%
  group_by(document) %>%
  top_n(1, n) %>%
  ungroup() %>%
  transmute(consensus = document, topic)

assignments <- augment(ap_lda, data = article_dtm)
assignments
```
El paso más importante es eliminar la incertidumbre y para ello se realiza el siguiente proceso: **Las palabras que contradigan al documento versus la ley seran expulsadas.**

```{r, echo=FALSE, cache=FALSE}
assignments <- assignments %>%
  inner_join(article_topics, by = c(".topic" = "topic"))
```

```{r, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE}
wrong_words <- assignments %>%
  filter(document != consensus)
art_title <- violations_art %>% 
  unnest_tokens(word, 
type) %>% 
  anti_join(stop_words)%>%
  select(c(art_principal,word))
article_gamma$document<-as.numeric(article_gamma$document)
art_title$art_principal<-as.numeric(art_title$art_principal)
lda_gamma <- full_join(article_gamma, art_title, by = c("document" = "art_principal"))
lda_gamma%>%
  arrange(gamma)

categories<-lda_gamma %>% 
  filter(!word %in% wrong_words$term)%>%
  anti_join(stop_words)%>%
  filter(gamma > 0.10)%>%
  arrange(document)%>%
  #distinct(word,.keep_all = TRUE)%>%
  ungroup()


article_classifications
```



```{r, echo=FALSE, cache=FALSE}
article_gamma$document<-as.numeric(article_gamma$document)
#art_title$article<-as.numeric(art_title$article)
article_gamma%>%
  count(topic,sort = TRUE)
lda_gamma <- full_join(article_gamma, art_title, by = c("document" = "art_principal"))
lda_gamma%>%
  filter(!is.na(word))->lda_gamma

```


Los targets estan completos

```{r, echo=FALSE, cache=FALSE}
ap_top_terms %>%
  filter(!term %in% wrong_words$term)%>%
  filter(term!=c("compliance"))%>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()
```



```{r, echo=FALSE, cache=FALSE}
ap_top_terms %>%
  filter(!term %in% wrong_words$term)%>%
  filter(term!=c("compliance"))%>%
  group_by(topic)%>%
  arrange(desc(beta))->final_categories


final_categories<-aggregate(final_categories$term, list(final_categories$topic), paste, collapse=",")
colnames(final_categories)[1]<-"topic"
colnames(final_categories)[2]<-"category"

final_categories
```

Con esto termino el `tidytuesday`, espero que les guste.

